#!/usr/bin/env python3
"""
Fixed Training Script for Mobile SMS Classifier
Improved data distribution and model architecture for better accuracy
TensorFlow Lite compatible design with batch size fix
"""

import os
import sys
import logging
import pandas as pd
import numpy as np
from pathlib import Path
from sklearn.model_selection import train_test_split
from sklearn.utils.class_weight import compute_class_weight

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def create_balanced_training_data():
    """Create balanced training data with equal samples per category"""
    
    logger.info("Creating balanced training data...")
    
    # SMS categories
    categories = {
        'INBOX': 0, 'SPAM': 1, 'OTP': 2, 
        'BANKING': 3, 'ECOMMERCE': 4, 'NEEDS_REVIEW': 5
    }
    
    training_data = []
    samples_per_category = 150  # Equal samples for each category
    
    # OTP Messages (Category 2) - Very distinctive patterns
    otp_patterns = [
        "is your OTP for", "is your verification code", "OTP:", "verification code:",
        "is your security code", "authentication code:", "is your PIN", "login OTP",
        "One Time Password", "valid for", "minutes", "expire", "do not share"
    ]
    
    otp_messages = []
    # Base OTP messages
    base_otps = [
        "{code} is your OTP for HDFC Bank. Valid for 10 minutes. Do not share.",
        "Your verification code is {code}. Valid for 5 minutes only.",
        "OTP: {code} for SBI login. Do not share with anyone.",
        "Use {code} to verify your account. One Time Password valid for 15 minutes.",
        "{code} is your security code for PayTM. Don't share with anyone.",
        "Dear Customer, {code} is your OTP for ICICI Bank. Valid till 10 mins.",
        "Your OTP is {code} for Amazon login. Valid for 10 minutes only.",
        "Verification code: {code}. Valid for 3 minutes. Do not share.",
        "{code} is your authentication code for Google. Expires in 5 minutes.",
        "Your login OTP is {code}. Valid for 10 minutes. Keep it confidential.",
        "OTP {code} for PhonePe transaction. Do not share with anyone.",
        "Code {code} to complete your registration. Valid for 5 mins.",
        "Your PIN is {code}. Use it to verify your identity.",
        "Authentication code: {code}. Expires in 10 minutes.",
        "Confirm with {code}. This code is valid for 15 minutes.",
        "{code} for your banking transaction. Expires in 10 minutes.",
        "Use {code} to complete login. Don't share this OTP.",
        "Your {app} verification code: {code}. Valid for 5 minutes.",
        "LOGIN CODE: {code}. Do not share with anyone.",
        "Security code {code} for account verification. Expires soon."
    ]
    
    # Generate OTP messages with random codes
    import random
    apps = ["WhatsApp", "Instagram", "Facebook", "Twitter", "PayTM", "PhonePe", "GPay", "HDFC", "SBI", "ICICI"]
    for i in range(samples_per_category):
        template = random.choice(base_otps)
        code = random.randint(100000, 999999)
        app = random.choice(apps)
        msg = template.format(code=code, app=app)
        otp_messages.append(msg)
    
    for msg in otp_messages:
        training_data.append((msg, categories['OTP']))
    
    # Banking Messages (Category 3) - Financial transactions
    banking_templates = [
        "Rs.{amount} debited from A/c XX{acc} on {date} by UPI/{phone}. Balance: Rs.{balance}",
        "Rs.{amount} credited to your account XX{acc} from {name} via UPI. Balance Rs.{balance}",
        "Dear Customer, Rs.{amount} has been debited from A/c {acc} for {purpose}. Balance Rs.{balance}",
        "IMPS transfer of Rs.{amount} from HDFC A/c XX{acc} to {name} successful. Ref: UPI{ref}",
        "Your SBI account XX{acc} credited with Rs.{amount} from SALARY on {date}. Available bal Rs.{balance}",
        "ATM withdrawal of Rs.{amount} from SBI ATM. A/c XX{acc} Balance Rs.{balance}",
        "EMI of Rs.{amount} debited from A/c XX{acc} for home loan. Balance Rs.{balance}",
        "Interest of Rs.{amount} credited to your savings account XX{acc}. Balance Rs.{balance}",
        "RTGS transfer of Rs.{amount} from A/c XX{acc} to BUSINESS ACCOUNT successful",
        "Card payment of Rs.{amount} at {merchant} declined. Insufficient balance.",
        "Your credit card bill of Rs.{amount} is due on {date}. Pay to avoid late fees.",
        "Minimum amount due Rs.{amount}. Pay by {date} to avoid charges.",
        "Auto-debit of Rs.{amount} for mutual fund SIP successful.",
        "Your fixed deposit of Rs.{amount} has matured. Interest Rs.{interest} credited.",
        "UPI payment of Rs.{amount} to {merchant} successful. Balance: Rs.{balance}",
        "NEFT transfer of Rs.{amount} initiated successfully. Reference: {ref}",
        "Cheque no. {cheque} for Rs.{amount} cleared. Balance: Rs.{balance}",
        "Mobile recharge of Rs.{amount} successful for {phone}. Balance: Rs.{balance}",
        "Bill payment of Rs.{amount} for {utility} successful. Balance: Rs.{balance}",
        "Online purchase of Rs.{amount} at {merchant}. Transaction successful."
    ]
    
    merchants = ["AMAZON", "FLIPKART", "SWIGGY", "ZOMATO", "BIG BAZAAR", "RELIANCE", "METRO", "DMart"]
    utilities = ["electricity", "gas", "water", "mobile", "broadband", "DTH"]
    names = ["JOHN", "RAVI", "PRIYA", "AMIT", "NEHA", "ROHIT", "ANJALI", "VIKASH"]
    
    for i in range(samples_per_category):
        template = random.choice(banking_templates)
        data = {
            'amount': random.randint(500, 50000),
            'acc': random.randint(1000, 9999),
            'date': f"{random.randint(1,28)}-{random.choice(['JAN','FEB','MAR','APR','MAY'])}-25",
            'phone': f"98{random.randint(10000000, 99999999)}",
            'balance': random.randint(10000, 100000),
            'name': random.choice(names),
            'purpose': random.choice(utilities + ["shopping", "fuel", "medicine"]),
            'merchant': random.choice(merchants),
            'ref': random.randint(100000, 999999),
            'interest': random.randint(100, 2000),
            'cheque': random.randint(100000, 999999),
            'utility': random.choice(utilities)
        }
        try:
            msg = template.format(**data)
            training_data.append((msg, categories['BANKING']))
        except KeyError:
            # Skip if template has unsupported placeholders
            continue
    
    # Spam Messages (Category 1) - Clear promotional/scam content
    spam_templates = [
        "üéâ CONGRATULATIONS! You've won Rs.{prize}! Call {phone} to claim your prize NOW!",
        "URGENT: You've won {item}! Click {link} to claim within 24 hours!",
        "LIMITED TIME OFFER! {discount}% OFF on everything! Shop now at {link}",
        "FREE {item} for first {num} customers! Call {phone} immediately!",
        "WINNER WINNER! You're selected for {item} worth Rs.{prize}! Call {phone} now!",
        "HURRY! Last chance to win {prize} CASH! SMS WIN to {shortcode}",
        "Congratulations winner! You won lottery prize. Click here to claim bonus money",
        "URGENT ALERT: Your account will be suspended. Click link to verify immediately",
        "FLASH SALE: Get {discount}% discount on {category}. Limited time offer. Buy now!",
        "You are pre-approved for credit card with {limit} lakh limit. Call now for instant approval",
        "AMAZING OFFER! Buy 1 Get 1 FREE! Limited stock. Order now!",
        "CHEAP {category} online. {discount}% discount. No prescription needed. Click link.",
        "Make money from home! Earn {amount} per month. No investment. Call now!",
        "URGENT: Account blocked. Update KYC immediately to avoid permanent closure.",
        "WIN BIG! Lottery ticket winner announced. Claim prize money now!",
        "üéÅ Special offer for you! Get {item} at {discount}% discount! Limited time!",
        "ALERT: Your {service} will expire today. Renew now to avoid disconnection!",
        "GUARANTEED LOAN APPROVAL! Get Rs.{amount} without documents. Call {phone}",
        "üî• HOTTEST DEALS! {category} starting at Rs.{price}! Don't miss out!",
        "INSTANT CASH! Get loan in 5 minutes. No verification needed. Apply now!"
    ]
    
    items = ["iPhone 15", "Laptop", "Car", "Bike", "Gold", "Diamond Ring", "Smart TV", "Air Conditioner"]
    categories_spam = ["mobiles", "electronics", "fashion", "medicines", "books", "groceries"]
    services = ["broadband", "DTH", "mobile plan", "electricity", "gas connection"]
    
    for i in range(samples_per_category):
        template = random.choice(spam_templates)
        data = {
            'prize': random.randint(10000, 500000),
            'phone': f"98{random.randint(10000000, 99999999)}",
            'item': random.choice(items),
            'link': f"http://bit.ly/{random.choice(['offer', 'claim', 'win'])}{random.randint(100,999)}",
            'discount': random.randint(50, 90),
            'num': random.randint(10, 100),
            'shortcode': random.randint(56789, 99999),
            'category': random.choice(categories_spam),
            'limit': random.randint(2, 10),
            'amount': random.randint(25000, 100000),
            'service': random.choice(services),
            'price': random.randint(100, 5000)
        }
        try:
            msg = template.format(**data)
            training_data.append((msg, categories['SPAM']))
        except KeyError:
            continue
    
    # E-commerce Messages (Category 4)
    ecommerce_templates = [
        "Your {platform} order #{order_id} is out for delivery. Expected by {time}. Track: {link}",
        "Order #{order_id} delivered successfully. Rate your experience on {platform} app",
        "Your {platform} order #{order_id} is shipped. Estimated delivery: {date}",
        "Payment of Rs.{amount} for order #{order_id} confirmed. Thank you for shopping with us!",
        "{platform}: Your order #{order_id} worth Rs.{amount} is being prepared for delivery",
        "{platform} delivery update: Your order from {restaurant} will arrive in {time} minutes",
        "Your {platform} ride receipt: Rs.{amount} for trip on {date}. Rate your driver",
        "{platform}: Rs.{amount} added to wallet. Use {code} for {discount}% cashback on next ride",
        "{platform}: Your grocery order #{order_id} will be delivered {timing}",
        "Your refund of Rs.{amount} for order #{order_id} has been processed to your account",
        "{platform} order update: Your {item} order is packed and ready for dispatch",
        "Return request approved for order #{order_id}. Refund of Rs.{amount} initiated",
        "Your {platform} subscription has been renewed. Next billing: Rs.{amount} on {date}",
        "Order #{order_id} is delayed. New expected delivery: {date}. Sorry for inconvenience",
        "{platform} cashback: Rs.{amount} credited to your wallet for order #{order_id}"
    ]
    
    platforms = ["Amazon", "Flipkart", "Myntra", "Zomato", "Swiggy", "Uber", "Ola", "BigBasket", "Grofers"]
    restaurants = ["McDonald's", "KFC", "Pizza Hut", "Domino's", "Subway", "Chinese Wok"]
    items = ["mobile", "laptop", "shoes", "shirt", "books", "groceries"]
    timings = ["tomorrow morning", "today evening", "within 2 hours"]
    
    for i in range(samples_per_category):
        template = random.choice(ecommerce_templates)
        data = {
            'platform': random.choice(platforms),
            'order_id': random.randint(10000000, 99999999),
            'time': f"{random.randint(1, 12)} PM",
            'link': f"amzn.to/track{random.randint(100,999)}",
            'date': f"{random.randint(15,30)}-Jan-25",
            'amount': random.randint(200, 5000),
            'restaurant': random.choice(restaurants),
            'code': f"CODE{random.randint(100,999)}",
            'discount': random.randint(10, 50),
            'timing': random.choice(timings),
            'item': random.choice(items)
        }
        try:
            msg = template.format(**data)
            training_data.append((msg, categories['ECOMMERCE']))
        except KeyError:
            continue
    
    # Inbox Messages (Category 0) - Important personal/business
    inbox_messages = [
        "Hi, are you free for lunch today? Let me know!",
        "Meeting rescheduled to 3 PM tomorrow. Please confirm attendance.",
        "Happy birthday! Hope you have a wonderful day ahead!",
        "Don't forget about the presentation at 10 AM today. Good luck!",
        "Thanks for your help with the project. Really appreciate it!",
        "Can you please send me the report by EOD? Thanks!",
        "Flight delay notification: Your flight AI 101 is delayed by 2 hours",
        "Your PNR 1234567890 for train journey on 20-Jan-25 is confirmed",
        "Appointment reminder: Doctor visit tomorrow at 4 PM. Bring reports",
        "Your electricity bill of Rs.1200 is due on 25th. Please pay to avoid disconnection",
        "Mom calling for dinner. Come home by 8 PM.",
        "Office party tomorrow at 7 PM. Please confirm your attendance.",
        "Interview scheduled for 10 AM on Monday. Good luck!",
        "Your car service is due. Please book appointment.",
        "Weather alert: Heavy rain expected. Carry umbrella.",
        "Reminder: Team meeting at 2 PM in conference room",
        "Happy anniversary! Best wishes for many more years together",
        "Movie tickets booked for 7 PM show. See you at the cinema",
        "Workshop on Machine Learning tomorrow. Don't forget to bring laptop",
        "Your package has arrived. Please collect from reception",
        "Congratulations on your promotion! Well deserved.",
        "Class cancelled today due to faculty unavailability",
        "Your gym membership expires next week. Renew soon",
        "Library books due for return by Friday. Avoid late fees",
        "Parent-teacher meeting scheduled for Saturday 10 AM"
    ]
    
    # Generate additional inbox messages
    additional_inbox = []
    subjects = ["meeting", "appointment", "reminder", "update", "invitation", "announcement"]
    for i in range(samples_per_category - len(inbox_messages)):
        if i % 6 == 0:
            additional_inbox.append(f"Important {random.choice(subjects)} scheduled for tomorrow. Please confirm.")
        elif i % 6 == 1:
            additional_inbox.append(f"Hi, just wanted to check if you received my message about the {random.choice(subjects)}.")
        elif i % 6 == 2:
            additional_inbox.append(f"Update: The {random.choice(subjects)} has been moved to next week.")
        elif i % 6 == 3:
            additional_inbox.append(f"Please review the documents for tomorrow's {random.choice(subjects)}.")
        elif i % 6 == 4:
            additional_inbox.append(f"Thank you for attending today's {random.choice(subjects)}. Follow-up soon.")
        else:
            additional_inbox.append(f"Don't forget about the {random.choice(subjects)} at {random.randint(9,17)} {'AM' if random.randint(9,17) < 12 else 'PM'}.")
    
    all_inbox = inbox_messages + additional_inbox
    for msg in all_inbox[:samples_per_category]:
        training_data.append((msg, categories['INBOX']))
    
    # Needs Review Messages (Category 5)
    review_messages = [
        "Please update your details to continue service.",
        "Important notice regarding your account.",
        "Action required for your profile verification.",
        "Your request has been processed successfully.",
        "Thank you for your recent transaction.",
        "We have received your application.",
        "Your booking is confirmed for today.",
        "Please contact customer service for assistance.",
        "Your subscription will expire soon.",
        "New features available in your account.",
        "Profile verification pending. Complete within 7 days.",
        "Document submitted successfully. Processing will take 2-3 days.",
        "Your feedback has been recorded. Thank you.",
        "Account security update completed successfully.",
        "New policy update. Please review and accept.",
        "Service maintenance scheduled for tomorrow 2-4 AM.",
        "Your recent inquiry is under review.",
        "Password changed successfully. If not done by you, contact support.",
        "Account settings updated as per your request.",
        "New terms and conditions effective from next month."
    ]
    
    # Generate additional review messages
    additional_review = []
    actions = ["verification", "update", "review", "confirmation", "approval"]
    for i in range(samples_per_category - len(review_messages)):
        if i % 5 == 0:
            additional_review.append(f"Your {random.choice(actions)} request is being processed.")
        elif i % 5 == 1:
            additional_review.append(f"Please complete the {random.choice(actions)} process.")
        elif i % 5 == 2:
            additional_review.append(f"System {random.choice(actions)} scheduled for maintenance.")
        elif i % 5 == 3:
            additional_review.append(f"Thank you for the {random.choice(actions)}. We'll get back soon.")
        else:
            additional_review.append(f"Additional {random.choice(actions)} may be required.")
    
    all_review = review_messages + additional_review
    for msg in all_review[:samples_per_category]:
        training_data.append((msg, categories['NEEDS_REVIEW']))
    
    logger.info(f"Generated {len(training_data)} training samples")
    
    # Show distribution
    label_counts = {}
    for _, label in training_data:
        label_counts[label] = label_counts.get(label, 0) + 1
    
    logger.info("Label distribution:")
    for category, idx in categories.items():
        logger.info(f"  {category}: {label_counts.get(idx, 0)} samples")
    
    return training_data

def train_fixed_model():
    """Train fixed model with better architecture and TFLite compatibility"""
    
    try:
        import tensorflow as tf
        from tensorflow.keras.models import Sequential
        from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, Dropout
        from tensorflow.keras.preprocessing.text import Tokenizer
        from tensorflow.keras.preprocessing.sequence import pad_sequences
        from sklearn.metrics import classification_report, confusion_matrix
        
        logger.info("Starting fixed model training...")
        
        # Create balanced training data
        training_data = create_balanced_training_data()
        
        # Separate texts and labels
        texts = [item[0] for item in training_data]
        labels = [item[1] for item in training_data]
        
        # Convert to DataFrame
        df = pd.DataFrame({'text': texts, 'label': labels})
        logger.info(f"Dataset shape: {df.shape}")
        
        # Split data with stratification
        X_train, X_test, y_train, y_test = train_test_split(
            df['text'], df['label'], test_size=0.2, random_state=42, stratify=df['label']
        )
        
        # Tokenization
        logger.info("Tokenizing text...")
        max_words = 5000  # Larger vocabulary for better representation
        max_len = 60      # Slightly longer sequences
        
        tokenizer = Tokenizer(num_words=max_words, oov_token='<OOV>')
        tokenizer.fit_on_texts(X_train)
        
        # Convert text to sequences
        X_train_seq = tokenizer.texts_to_sequences(X_train)
        X_test_seq = tokenizer.texts_to_sequences(X_test)
        
        # Pad sequences
        X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post', truncating='post')
        X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post', truncating='post')
        
        logger.info(f"Training shape: {X_train_pad.shape}")
        logger.info(f"Test shape: {X_test_pad.shape}")
        
        # Calculate class weights for balanced training
        class_weights = compute_class_weight(
            'balanced', 
            classes=np.unique(y_train), 
            y=y_train
        )
        class_weight_dict = dict(zip(np.unique(y_train), class_weights))
        logger.info(f"Class weights: {class_weight_dict}")
        
        # Build fixed TFLite-compatible model with dynamic batch size
        logger.info("Building fixed TFLite-compatible model...")
        
        # Use None for batch size to allow dynamic batch sizes
        model = Sequential([
            Embedding(max_words, 64),  # Larger embedding, no input_length
            GlobalAveragePooling1D(),  # TFLite-compatible sequence processing
            Dense(128, activation='relu'),  # Larger hidden layer
            Dropout(0.5),
            Dense(64, activation='relu'),
            Dropout(0.3),
            Dense(32, activation='relu'),
            Dropout(0.2),
            Dense(6, activation='softmax')  # 6 categories
        ])
        
        model.compile(
            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy']
        )
        
        logger.info("Fixed model architecture:")
        model.summary()
        
        # Train model with class weights and callbacks
        logger.info("Training fixed model...")
        from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
        
        callbacks = [
            EarlyStopping(
                monitor='val_accuracy',
                patience=10,
                restore_best_weights=True
            ),
            ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.5,
                patience=5,
                min_lr=0.0001
            )
        ]
        
        history = model.fit(
            X_train_pad, y_train,
            batch_size=32,  # Smaller batch size for better learning
            epochs=30,  # More epochs with early stopping
            validation_split=0.2,
            class_weight=class_weight_dict,  # Balance classes during training
            callbacks=callbacks,
            verbose=1
        )
        
        # Evaluate model
        logger.info("Evaluating fixed model...")
        test_loss, test_acc = model.evaluate(X_test_pad, y_test, verbose=0)
        logger.info(f"Test accuracy: {test_acc:.4f}")
        
        # Predictions and detailed analysis
        y_pred = model.predict(X_test_pad, verbose=0)
        y_pred_classes = np.argmax(y_pred, axis=1)
        
        # Classification report
        category_names = ['INBOX', 'SPAM', 'OTP', 'BANKING', 'ECOMMERCE', 'NEEDS_REVIEW']
        print("\nClassification Report:")
        print(classification_report(y_test, y_pred_classes, target_names=category_names, zero_division=0))
        
        # Confusion matrix
        cm = confusion_matrix(y_test, y_pred_classes)
        logger.info("Confusion Matrix:")
        logger.info(f"Categories: {category_names}")
        for i, row in enumerate(cm):
            logger.info(f"{category_names[i]}: {row}")
        
        # Save model
        models_dir = Path("models")
        models_dir.mkdir(exist_ok=True)
        
        model_path = models_dir / "fixed_sms_classifier.keras"
        model.save(str(model_path))
        logger.info(f"Fixed model saved to {model_path}")
        
        # Save tokenizer
        import pickle
        tokenizer_path = models_dir / "fixed_tokenizer.pkl"
        with open(tokenizer_path, 'wb') as f:
            pickle.dump(tokenizer, f)
        logger.info(f"Fixed tokenizer saved to {tokenizer_path}")
        
        # Convert to TensorFlow Lite with dynamic shapes
        logger.info("Converting fixed model to TensorFlow Lite...")
        converter = tf.lite.TFLiteConverter.from_keras_model(model)
        
        # Configure for mobile compatibility
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        converter.target_spec.supported_ops = [
            tf.lite.OpsSet.TFLITE_BUILTINS,
            tf.lite.OpsSet.SELECT_TF_OPS
        ]
        
        # IMPORTANT: Set dynamic batch size - this allows TFLite to work with any batch size
        converter.target_spec.supported_types = [tf.float32]
        
        tflite_model = converter.convert()
        
        tflite_path = models_dir / "fixed_sms_classifier.tflite"
        with open(tflite_path, 'wb') as f:
            f.write(tflite_model)
        
        size_mb = len(tflite_model) / (1024 * 1024)
        logger.info(f"Fixed TFLite model saved to {tflite_path}")
        logger.info(f"Fixed model size: {size_mb:.2f}MB")
        
        # Test TFLite model with a single sample (fixing previous error)
        logger.info("Testing fixed TensorFlow Lite model...")
        interpreter = tf.lite.Interpreter(model_content=tflite_model)
        interpreter.allocate_tensors()
        
        # Get input and output details
        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()
        
        logger.info(f"TFLite Input: {input_details}")
        logger.info(f"TFLite Output: {output_details}")
        
        # Test with diverse samples
        test_samples = [
            ("Your OTP is 456789. Valid for 10 minutes. Do not share.", "OTP"),
            ("üéâ CONGRATULATIONS! You've won Rs.100000! Call 9876543210 NOW!", "SPAM"),
            ("Hi, are you free for lunch today? Let me know!", "INBOX"),
            ("Rs.15000 debited from A/c XX1234 on 15-JAN-25. Balance: Rs.45000", "BANKING"),
            ("Your Amazon order #12345678 is out for delivery. Expected by 6 PM.", "ECOMMERCE"),
            ("Please update your profile details to continue service.", "NEEDS_REVIEW")
        ]
        
        logger.info("Sample predictions:")
        correct_predictions = 0
        for text, expected in test_samples:
            # Preprocess
            sample_seq = tokenizer.texts_to_sequences([text])
            sample_pad = pad_sequences(sample_seq, maxlen=max_len, padding='post', truncating='post')
            
            # Resize the interpreter for the current batch size
            input_shape = sample_pad.shape
            interpreter.resize_tensor_input(input_details[0]['index'], input_shape)
            interpreter.allocate_tensors()
            
            # Predict
            interpreter.set_tensor(input_details[0]['index'], sample_pad.astype(np.float32))
            interpreter.invoke()
            
            output_data = interpreter.get_tensor(output_details[0]['index'])
            predicted_class = np.argmax(output_data[0])
            confidence = np.max(output_data[0])
            predicted_category = category_names[predicted_class]
            
            is_correct = predicted_category == expected
            if is_correct:
                correct_predictions += 1
            
            logger.info(f"  Text: {text[:50]}...")
            logger.info(f"  Expected: {expected}, Predicted: {predicted_category} ({confidence:.3f}) {'‚úì' if is_correct else '‚úó'}")
        
        sample_accuracy = correct_predictions / len(test_samples)
        logger.info(f"Sample test accuracy: {sample_accuracy:.1%}")
        
        # Create fixed metadata
        metadata = {
            'model_type': 'Fixed Dense Network',
            'categories': category_names,
            'max_words': max_words,
            'max_len': max_len,
            'test_accuracy': float(test_acc),
            'sample_test_accuracy': float(sample_accuracy),
            'model_size_mb': float(size_mb),
            'training_samples': len(training_data),
            'samples_per_category': len(training_data) // 6,
            'architecture': 'Embedding + GlobalAveragePooling1D + 3x Dense layers',
            'features': ['balanced_dataset', 'class_weights', 'early_stopping', 'learning_rate_scheduling', 'dynamic_batch_size'],
            'class_weights': {str(k): float(v) for k, v in class_weight_dict.items()}  # Convert to JSON-serializable format
        }
        
        import json
        metadata_path = models_dir / "fixed_model_metadata.json"
        with open(metadata_path, 'w') as f:
            json.dump(metadata, f, indent=2)
        logger.info(f"Fixed metadata saved to {metadata_path}")
        
        logger.info("üéâ Fixed training completed successfully!")
        logger.info(f"üì± Mobile-ready fixed model: {size_mb:.2f}MB")
        logger.info(f"üéØ Test accuracy: {test_acc:.1%}")
        logger.info(f"üéØ Sample test accuracy: {sample_accuracy:.1%}")
        
        # Create a simple Android inference example
        logger.info("Creating Android integration example...")
        kotlin_path = models_dir / "TFLiteInferenceExample.kt"
        kotlin_code = """
package com.example.smartsmsfilter

import android.content.Context
import org.tensorflow.lite.Interpreter
import java.io.FileInputStream
import java.nio.ByteBuffer
import java.nio.channels.FileChannel
import java.nio.MappedByteBuffer
import java.nio.ByteOrder
import java.io.File
import java.io.IOException

/**
 * TensorFlow Lite Inference Engine for SMS Classification
 */
class TFLiteInferenceEngine(private val context: Context) {

    private var interpreter: Interpreter? = null
    private val maxWords = 5000
    private val maxLength = 60
    private val categories = listOf("INBOX", "SPAM", "OTP", "BANKING", "ECOMMERCE", "NEEDS_REVIEW")
    
    /**
     * Initialize the TFLite interpreter
     */
    init {
        try {
            val modelBuffer = loadModelFile("fixed_sms_classifier.tflite")
            val options = Interpreter.Options()
            interpreter = Interpreter(modelBuffer, options)
            println("TFLite model loaded successfully")
        } catch (e: Exception) {
            println("Error loading TFLite model: ${e.message}")
            // Fallback to rule-based classification if TFLite fails
        }
    }
    
    /**
     * Load TFLite model from assets
     */
    @Throws(IOException::class)
    private fun loadModelFile(modelName: String): MappedByteBuffer {
        val fileDescriptor = context.assets.openFd(modelName)
        val inputStream = FileInputStream(fileDescriptor.fileDescriptor)
        val fileChannel = inputStream.channel
        val startOffset = fileDescriptor.startOffset
        val declaredLength = fileDescriptor.declaredLength
        return fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength)
    }
    
    /**
     * Classify SMS message
     * @param message SMS text to classify
     * @return Pair of category and confidence score
     */
    fun classifySMS(message: String): Pair<String, Float> {
        // If TFLite model failed to load, use rule-based fallback
        if (interpreter == null) {
            return classifyWithRules(message)
        }
        
        try {
            // Preprocess input (tokenization would need custom implementation)
            // Here we're using a simplified approach for demonstration
            val input = preprocessInput(message)
            
            // Output buffer
            val outputBuffer = Array(1) { FloatArray(categories.size) }
            
            // Run inference
            interpreter?.run(input, outputBuffer)
            
            // Find category with highest confidence
            var maxIndex = 0
            var maxConfidence = outputBuffer[0][0]
            
            for (i in 1 until categories.size) {
                if (outputBuffer[0][i] > maxConfidence) {
                    maxConfidence = outputBuffer[0][i]
                    maxIndex = i
                }
            }
            
            return Pair(categories[maxIndex], maxConfidence)
            
        } catch (e: Exception) {
            println("Error during inference: ${e.message}")
            // Fallback to rule-based classification
            return classifyWithRules(message)
        }
    }
    
    /**
     * Preprocess input text for the model
     * Note: In a real implementation, you would use the same tokenizer used during training
     */
    private fun preprocessInput(message: String): Array<ByteBuffer> {
        // This is a placeholder for actual tokenization logic
        // You would need to implement proper tokenization matching your Python code
        
        val inputBuffer = ByteBuffer.allocateDirect(4 * maxLength)
        inputBuffer.order(ByteOrder.nativeOrder())
        
        // Clear buffer
        inputBuffer.rewind()
        
        // For simplicity, just populate with dummy data
        // In reality, you would tokenize the text using the same approach as in training
        for (i in 0 until maxLength) {
            inputBuffer.putFloat(0f)
        }
        
        // Prepare input array
        return Array(1) { inputBuffer }
    }
    
    /**
     * Rule-based classification as fallback
     */
    private fun classifyWithRules(message: String): Pair<String, Float> {
        val lowerMessage = message.toLowerCase()
        
        // Simple rule-based classification
        return when {
            lowerMessage.contains("otp") || lowerMessage.contains("code") || lowerMessage.contains("verification") -> 
                Pair("OTP", 0.8f)
                
            lowerMessage.contains("congratulations") || lowerMessage.contains("won") || 
                    lowerMessage.contains("offer") || lowerMessage.contains("discount") || 
                    lowerMessage.contains("free") || lowerMessage.contains("cash") -> 
                Pair("SPAM", 0.8f)
                
            lowerMessage.contains("debited") || lowerMessage.contains("credited") || 
                    lowerMessage.contains("account") || lowerMessage.contains("bank") || 
                    lowerMessage.contains("balance") -> 
                Pair("BANKING", 0.8f)
                
            lowerMessage.contains("order") || lowerMessage.contains("delivery") || 
                    lowerMessage.contains("shipped") || lowerMessage.contains("amazon") || 
                    lowerMessage.contains("flipkart") -> 
                Pair("ECOMMERCE", 0.8f)
                
            lowerMessage.contains("update") || lowerMessage.contains("profile") || 
                    lowerMessage.contains("service") || lowerMessage.contains("details") -> 
                Pair("NEEDS_REVIEW", 0.6f)
                
            else -> Pair("INBOX", 0.5f)
        }
    }
    
    /**
     * Close the interpreter when done
     */
    fun close() {
        interpreter?.close()
        interpreter = null
    }
}
"""
        with open(kotlin_path, "w") as f:
            f.write(kotlin_code)
        logger.info(f"Android integration example created at {kotlin_path}")
        
        return {
            'model_path': str(model_path),
            'tflite_path': str(tflite_path),
            'tokenizer_path': str(tokenizer_path),
            'test_accuracy': test_acc,
            'sample_accuracy': sample_accuracy,
            'model_size_mb': size_mb,
            'android_example': str(kotlin_path)
        }
        
    except Exception as e:
        logger.error(f"Fixed training failed: {e}")
        import traceback
        traceback.print_exc()
        return None

def main():
    """Main fixed training function"""
    logger.info("üöÄ Fixed SMS Classifier Training")
    logger.info("=" * 60)
    
    # Train fixed model
    result = train_fixed_model()
    
    if result:
        print("\n" + "="*60)
        print("‚úÖ SUCCESS: Fixed Mobile SMS Classifier Trained!")
        print("="*60)
        print(f"üìÅ Model files:")
        print(f"  ‚Ä¢ Keras model: {result['model_path']}")
        print(f"  ‚Ä¢ TFLite model: {result['tflite_path']} ({result['model_size_mb']:.2f}MB)")
        print(f"  ‚Ä¢ Tokenizer: {result['tokenizer_path']}")
        print(f"üéØ Test accuracy: {result['test_accuracy']:.1%}")
        print(f"üéØ Sample test accuracy: {result['sample_accuracy']:.1%}")
        print(f"üì± Ready for Android integration!")
        print("="*60)
        print(f"üîß Next steps:")
        print(f"  1. Copy {Path(result['tflite_path']).name} to android/app/src/main/assets/")
        print(f"  2. Implement TFLiteInferenceEngine.kt (example at {result['android_example']})")
        print(f"  3. Test with real SMS messages in Android app")
        print("="*60)
        print("üìä Improvements made:")
        print("  ‚Ä¢ Fixed TFLite dynamic batch size issue")
        print("  ‚Ä¢ Balanced dataset (150 samples per category)")
        print("  ‚Ä¢ Class weights for balanced training")
        print("  ‚Ä¢ Enhanced architecture with larger layers")
        print("  ‚Ä¢ Early stopping and learning rate scheduling")
        print("  ‚Ä¢ Better data diversity and realistic patterns")
        print("  ‚Ä¢ Added Android integration example")
        print("="*60)
    else:
        print("\n‚ùå Fixed training failed. Please check the logs above.")

if __name__ == "__main__":
    main()