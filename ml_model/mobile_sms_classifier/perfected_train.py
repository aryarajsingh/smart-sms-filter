#!/usr/bin/env python3
"""
Perfected Enhanced SMS Classifier Training Script
Combines the best data from enhanced model with the optimal architecture from fixed model
Target: Achieve 98%+ accuracy with enhanced diverse data
"""

import os
import sys
import logging
import pandas as pd
import numpy as np
from pathlib import Path
from sklearn.model_selection import train_test_split
from sklearn.utils.class_weight import compute_class_weight
import random

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def create_high_quality_synthetic_data():
    """Create high-quality synthetic training data optimized for accuracy"""
    
    logger.info("Creating high-quality synthetic training data...")
    
    # SMS categories
    categories = {
        'INBOX': 0, 'SPAM': 1, 'OTP': 2, 
        'BANKING': 3, 'ECOMMERCE': 4, 'NEEDS_REVIEW': 5
    }
    
    training_data = []
    samples_per_category = 200  # Keep enhanced data volume
    
    # ============= HIGH-QUALITY OTP MESSAGES =============
    logger.info("Generating high-quality OTP messages...")
    
    # Focus on CLEAR, DISTINCTIVE OTP patterns
    otp_templates = [
        # Standard clear formats (most common)
        "{code} is your OTP for {service}. Valid for {time} minutes. Do not share.",
        "Your OTP is {code} for {service}. Valid for {time} minutes only.",
        "OTP: {code} for {service} login. Do not share with anyone.",
        "Verification code: {code}. Valid for {time} minutes. Do not share.",
        "{code} is your security code for {service}. Don't share with anyone.",
        "Your login OTP is {code}. Valid for {time} minutes. Keep it confidential.",
        "Authentication code: {code}. Expires in {time} minutes.",
        "Use {code} to verify your account. One Time Password valid for {time} minutes.",
        
        # Short clear formats
        "OTP {code}",
        "Code: {code}",
        "{service}: {code}",
        "Verify: {code}",
        
        # Security focused (clear patterns)
        "LOGIN CODE: {code}. Do not share with anyone.",
        "Security code {code} for account verification.",
        "URGENT: Use {code} to secure your {service} account",
        
        # Common variations but clear
        "Dear Customer, {code} is your OTP for {service}.",
        "Hi! {code} is your {service} verification code",
        "{service} verification: {code}",
        "Confirm with {code}. Valid for {time} minutes.",
    ]
    
    # Keep service list focused and realistic
    services = [
        "HDFC Bank", "SBI", "ICICI Bank", "Axis Bank", "PayTM", "PhonePe", "GPay", 
        "WhatsApp", "Instagram", "Facebook", "Amazon", "Flipkart", "Google"
    ]
    
    for i in range(samples_per_category):
        template = random.choice(otp_templates)
        code = random.choice([
            str(random.randint(1000, 9999)),      # 4-digit (most common)
            str(random.randint(100000, 999999)),  # 6-digit (very common)
        ])
        service = random.choice(services)
        time = random.choice([2, 3, 5, 10, 15])  # Most common time limits
        
        try:
            msg = template.format(code=code, service=service, time=time)
            training_data.append((msg, categories['OTP']))
        except:
            msg = f"{code} is your OTP for {service}. Valid for {time} minutes."
            training_data.append((msg, categories['OTP']))
    
    # ============= HIGH-QUALITY BANKING MESSAGES =============
    logger.info("Generating high-quality Banking messages...")
    
    # Focus on CLEAR banking patterns
    banking_templates = [
        # Most common transaction patterns
        "Rs.{amount} debited from A/c XX{acc} on {date}. Balance: Rs.{balance}",
        "Rs.{amount} credited to your account XX{acc} from {name}. Balance Rs.{balance}",
        "ATM withdrawal of Rs.{amount} from {bank} ATM. A/c XX{acc} Balance Rs.{balance}",
        "UPI payment of Rs.{amount} to {merchant} successful. Balance: Rs.{balance}",
        "Card payment of Rs.{amount} at {merchant}. Transaction successful.",
        "Your {bank} credit card bill of Rs.{amount} is due on {date}.",
        "EMI of Rs.{amount} debited from A/c XX{acc} for loan. Balance Rs.{balance}",
        "Salary of Rs.{amount} credited to your {bank} account. Balance Rs.{balance}",
        "Mobile recharge of Rs.{amount} successful. Balance: Rs.{balance}",
        "IMPS transfer of Rs.{amount} from {bank} A/c XX{acc} successful.",
        
        # Clear banking alerts
        "Low balance alert: Your {bank} A/c XX{acc} balance is Rs.{balance}",
        "Transaction of Rs.{amount} declined due to insufficient balance",
        "Fixed deposit of Rs.{amount} matured. Interest Rs.{interest} credited.",
        "Auto-debit of Rs.{amount} for {purpose} successful.",
        "Cheque no. {cheque} for Rs.{amount} cleared. Balance Rs.{balance}",
        
        # UPI specific (very common now)
        "UPI payment of Rs.{amount} via {app} successful. Balance: Rs.{balance}",
        "UPI received Rs.{amount} from {name}. A/c balance: Rs.{balance}",
        "UPI AutoPay of Rs.{amount} for {purpose} activated successfully",
        "UPI payment failed. Please try again or contact bank",
        "Your UPI ID {name}@{app} linked successfully",
    ]
    
    banks = ["HDFC", "SBI", "ICICI", "Axis", "Kotak", "Yes Bank", "PNB"]
    merchants = ["Amazon", "Flipkart", "Swiggy", "Zomato", "DMart", "Reliance"]
    names = ["RAVI", "PRIYA", "AMIT", "NEHA", "ROHIT", "ANJALI"]
    apps = ["PayTM", "PhonePe", "GPay", "BHIM"]
    purposes = ["Netflix", "mobile", "electricity", "gas", "insurance"]
    
    for i in range(samples_per_category):
        template = random.choice(banking_templates)
        data = {
            'amount': random.choice([
                random.randint(50, 500),      # Small amounts
                random.randint(500, 5000),    # Medium amounts
                random.randint(5000, 50000),  # Large amounts
            ]),
            'acc': random.randint(1000, 9999),
            'date': f"{random.randint(1,28)}-{random.choice(['JAN','FEB','MAR'])}-25",
            'balance': random.randint(1000, 100000),
            'name': random.choice(names),
            'merchant': random.choice(merchants),
            'bank': random.choice(banks),
            'app': random.choice(apps),
            'purpose': random.choice(purposes),
            'interest': random.randint(100, 2000),
            'cheque': random.randint(100000, 999999)
        }
        
        try:
            msg = template.format(**data)
            training_data.append((msg, categories['BANKING']))
        except:
            continue
    
    # ============= HIGH-QUALITY SPAM MESSAGES =============
    logger.info("Generating high-quality SPAM messages...")
    
    # Focus on CLEAR spam patterns with obvious indicators
    spam_templates = [
        # Prize/lottery scams (very clear)
        "üéâ CONGRATULATIONS! You've won Rs.{prize}! Call {phone} to claim NOW!",
        "WINNER WINNER! You're selected for {item} worth Rs.{prize}! Call {phone}",
        "URGENT: You've won {item}! Click {link} to claim within 24 hours!",
        "Lottery winner announced! You won Rs.{prize}. SMS WIN to {shortcode}",
        "üéÅ You're today's lucky winner! Get {item} FREE! Call {phone} now!",
        
        # Fake offers (obvious spam)
        "LIMITED TIME! {discount}% OFF on everything! Shop now at {link}",
        "FLASH SALE: Get {discount}% discount on everything. Buy now!",
        "AMAZING OFFER! Buy 1 Get {num} FREE! Limited stock. Order now!",
        "üî• HOTTEST DEALS! Everything starting at Rs.{price}! Don't miss!",
        "MEGA SALE: Up to {discount}% off on everything. Hurry!",
        
        # Fake urgency (clear spam indicators)
        "URGENT ALERT: Your account will be suspended. Click {link} immediately",
        "FINAL NOTICE: Pay Rs.{amount} to avoid disconnection",
        "IMMEDIATE ACTION REQUIRED: Update KYC to avoid account block",
        "Security breach detected! Verify at {link} within 2 hours",
        
        # Loan scams (obvious)
        "GUARANTEED LOAN! Get Rs.{amount} without documents. Call {phone}",
        "Instant cash! Rs.{amount} approved. No verification needed",
        "Pre-approved loan of Rs.{amount}. Call {phone} for instant money",
        "Easy loan! Rs.{amount} in 15 minutes. Apply now!",
        
        # Job/earning scams
        "Make Rs.{amount} from home! No investment required. Call {phone}",
        "Part time job! Earn Rs.{amount} daily. SMS JOIN to {shortcode}",
        "Work from home opportunity! Rs.{amount} per month guaranteed",
        
        # Investment scams
        "Double your money in {days} days! Invest Rs.{amount} get Rs.{prize}",
        "Stock tip: Guaranteed {percent}% profit! Buy now!",
        
        # Fake services
        "FREE {item}! Just pay delivery Rs.{amount}. Order now!",
        "CHEAP medicines online! {discount}% off. No prescription needed",
        
        # Modern scams
        "Your Aadhaar is suspended. Update immediately at {link}",
        "PAN card verification pending. Complete at {link}",
        "Legal notice: Pay Rs.{amount} fine or face arrest",
        "Your SIM will be blocked. Call {phone} to resolve",
    ]
    
    items = ["iPhone", "Laptop", "Car", "Gold", "TV", "AC"]
    
    for i in range(samples_per_category):
        template = random.choice(spam_templates)
        data = {
            'prize': random.randint(10000, 500000),
            'phone': f"98{random.randint(10000000, 99999999)}",
            'item': random.choice(items),
            'link': f"http://bit.ly/{random.choice(['offer', 'claim', 'win'])}{random.randint(100,999)}",
            'discount': random.randint(50, 90),
            'num': random.randint(1, 5),
            'shortcode': random.randint(56789, 99999),
            'price': random.randint(99, 999),
            'amount': random.randint(1000, 50000),
            'days': random.choice([7, 15, 30]),
            'percent': random.randint(100, 500)
        }
        
        try:
            msg = template.format(**data)
            training_data.append((msg, categories['SPAM']))
        except:
            continue
    
    # ============= HIGH-QUALITY ECOMMERCE MESSAGES =============
    logger.info("Generating high-quality E-commerce messages...")
    
    # Focus on CLEAR e-commerce patterns
    ecommerce_templates = [
        # Order updates (most common)
        "Your {platform} order #{order_id} is out for delivery. Expected by {time}",
        "Order #{order_id} delivered successfully. Rate your experience on {platform}",
        "Your {platform} order #{order_id} is shipped. Track: {link}",
        "Payment of Rs.{amount} for order #{order_id} confirmed. Thank you!",
        "{platform}: Your order worth Rs.{amount} is being prepared",
        "Order #{order_id} is delayed. New delivery: {date}. Sorry!",
        
        # Delivery updates
        "{platform} delivery: Your order will arrive in {time} minutes",
        "Your order from {restaurant} is ready for pickup",
        "Delivery partner assigned for order #{order_id}",
        "Failed delivery attempt for #{order_id}. Reschedule?",
        
        # Ride services  
        "Your {platform} ride receipt: Rs.{amount} for trip on {date}",
        "Trip completed! Rs.{amount} charged to your wallet",
        "Your {platform} driver will arrive in {time} minutes",
        "Ride cancelled. Rs.{amount} refunded to account",
        
        # Wallet and payments
        "{platform}: Rs.{amount} added to wallet successfully",
        "Cashback of Rs.{amount} credited for order #{order_id}",
        "Use code {code} for {discount}% off on next order",
        "Payment failed for order #{order_id}. Try different method",
        
        # Returns and refunds
        "Return approved for #{order_id}. Refund Rs.{amount} initiated",
        "Your refund of Rs.{amount} processed to your account",
        "Replacement for order #{order_id} will be delivered by {date}",
        
        # Subscriptions
        "Your {platform} subscription renewed. Next billing: Rs.{amount}",
        "{platform} Plus membership activated. Enjoy free delivery!",
        "Subscription expires in {days} days. Renew to continue",
    ]
    
    platforms = ["Amazon", "Flipkart", "Myntra", "Swiggy", "Zomato", "Uber", "Ola", "BigBasket"]
    restaurants = ["McDonald's", "KFC", "Pizza Hut", "Domino's", "Subway"]
    
    for i in range(samples_per_category):
        template = random.choice(ecommerce_templates)
        data = {
            'platform': random.choice(platforms),
            'order_id': random.randint(10000000, 99999999),
            'time': random.choice(["6 PM", "30", "45"]),
            'link': f"amzn.to/track{random.randint(100,999)}",
            'date': f"{random.randint(15,30)}-Jan-25",
            'amount': random.randint(99, 5000),
            'restaurant': random.choice(restaurants),
            'code': f"CODE{random.randint(100,999)}",
            'discount': random.randint(10, 50),
            'days': random.randint(1, 30)
        }
        
        try:
            msg = template.format(**data)
            training_data.append((msg, categories['ECOMMERCE']))
        except:
            continue
    
    # ============= HIGH-QUALITY INBOX MESSAGES =============
    logger.info("Generating high-quality INBOX messages...")
    
    # Focus on CLEAR personal/work messages
    inbox_templates = [
        # Personal (very clear)
        "Hi, are you free for lunch today? Let me know!",
        "Thanks for your help with the project. Really appreciate it!",
        "Happy birthday! Hope you have a wonderful day ahead!",
        "Don't forget about the meeting at {time} today. Good luck!",
        "Can you please send me the report by EOD? Thanks!",
        "Mom calling for dinner. Come home by {time}",
        "How was your day? Call me when you're free",
        "Missing you! When are you visiting home?",
        "Made your favorite dish today. Come for dinner",
        
        # Work/Office (clear patterns)
        "Team meeting at {time} in conference room",
        "Client presentation moved to {time}. Prepare accordingly",  
        "Your leave application approved for {date}",
        "Office party tomorrow at {time}. Please confirm",
        "Interview scheduled for {time} on Monday. Good luck!",
        "Salary credited to your account. Check payslip",
        "New project assigned. Check email for details",
        "Work from home approved for {date}",
        
        # Travel and bookings
        "Flight delay: Your flight {flight} delayed by {time} hours",
        "Your PNR {pnr} for train journey on {date} is confirmed",
        "Hotel booking confirmed for {date}. Check in after 2 PM",
        "Cab booked for {time}. Driver will call you",
        
        # Appointments
        "Appointment reminder: Doctor visit at {time}. Bring reports",
        "Your car service is due. Please book appointment",
        "Dental checkup scheduled for {date} at {time}",
        "Gym session booked for {time}. Don't miss it!",
        
        # Utilities (personal notifications)
        "Your electricity bill of Rs.{amount} is due on {date}",
        "Gas cylinder booking confirmed. Delivery by {date}",
        "Internet maintenance on {date} from {time}",
        "Your broadband plan expires on {date}. Renew soon",
        
        # Educational
        "Class cancelled today due to faculty unavailability",
        "Exam scheduled for {date}. Prepare well",
        "Library books due by {date}. Avoid late fees",
        "Assignment submission deadline: {date}",
        
        # Social and events
        "Movie tickets booked for {time} show. See you!",
        "Party at my place this weekend. You're invited!",
        "Wedding invitation for {date}. Save the date!",
        "Birthday party tomorrow at {time}. Come!",
        
        # Simple friendly
        "Let's meet for coffee sometime",
        "Thanks for yesterday's help",
        "See you at the party tonight",
        "Good luck with your presentation!",
        "Hope you're doing well. Let's catch up",
    ]
    
    times = ["9 AM", "2 PM", "6 PM", "7 PM"]
    dates = [f"{random.randint(15,30)}-Jan-25", f"{random.randint(1,28)}-Feb-25"]
    
    for i in range(samples_per_category):
        if i < len(inbox_templates):
            template = inbox_templates[i]
        else:
            template = random.choice(inbox_templates)
            
        data = {
            'time': random.choice(times),
            'date': random.choice(dates),
            'amount': random.randint(500, 3000),
            'flight': f"AI{random.randint(100,999)}",
            'pnr': random.randint(1000000000, 9999999999),
        }
        
        try:
            msg = template.format(**data)
            training_data.append((msg, categories['INBOX']))
        except:
            simple_messages = [
                "Hi, how are you doing?",
                "Let's meet for coffee sometime", 
                "Thanks for your help yesterday",
                "See you at the meeting today",
                "Hope you're doing well!"
            ]
            msg = random.choice(simple_messages)
            training_data.append((msg, categories['INBOX']))
    
    # ============= HIGH-QUALITY NEEDS_REVIEW MESSAGES =============
    logger.info("Generating high-quality NEEDS_REVIEW messages...")
    
    # Focus on CLEAR service/account messages
    review_templates = [
        # Account related (clear patterns)
        "Please update your details to continue service",
        "Important notice regarding your account",
        "Action required for your profile verification",
        "Your request has been processed successfully",
        "Thank you for your recent transaction", 
        "We have received your application",
        "Your booking is confirmed for today",
        "Please contact customer service for assistance",
        "Your subscription will expire soon",
        "New features available in your account",
        
        # Verification (clear)
        "Profile verification pending. Complete within {days} days",
        "Document submitted successfully. Processing will take {days} days",
        "Your KYC verification is under review",
        "Identity verification completed successfully",
        "Address proof verification pending",
        "Your application is under review",
        
        # System notifications
        "Your feedback has been recorded. Thank you",
        "Account security update completed successfully",
        "Service maintenance scheduled for tomorrow",
        "Your recent inquiry is under review",
        "Account settings updated successfully",
        "Privacy policy updated. Please review changes",
        
        # Service related
        "Service request #{ticket} created successfully",
        "Your issue escalated to senior team",
        "Resolution time: {days} business days",
        "Technical team working on your issue",
        "Your service will be activated within {days} hours",
        "Service downtime expected on {date}",
        
        # Generic business
        "Message delivered successfully",
        "Your submission has been acknowledged",
        "We value your association with us",
        "Thank you for choosing our services",
        "Your appointment is confirmed",
        "Status updated to: In Progress",
        
        # Government/official
        "Your application reference: {ref}",
        "Please visit office with original documents",
        "Your certificate will be ready in {days} days",
        "Fee payment confirmation received",
        "Your registration is successful",
        
        # Modern services
        "Verification email sent to your registered email",
        "Your preferences have been saved",
        "Account sync completed",
        "Backup created successfully",
        "Monthly statement is ready",
        "Your plan details have been updated",
    ]
    
    for i in range(samples_per_category):
        if i < len(review_templates):
            template = review_templates[i]
        else:
            template = random.choice(review_templates)
            
        data = {
            'days': random.randint(1, 10),
            'ticket': random.randint(100000, 999999),
            'date': random.choice(dates),
            'ref': random.randint(10000, 99999)
        }
        
        try:
            msg = template.format(**data)
            training_data.append((msg, categories['NEEDS_REVIEW']))
        except:
            simple_review = [
                "Your request is being processed",
                "Thank you for contacting us",
                "Your application is under review",
                "Service will be activated soon"
            ]
            msg = random.choice(simple_review)
            training_data.append((msg, categories['NEEDS_REVIEW']))
    
    logger.info(f"Generated {len(training_data)} high-quality training samples")
    
    # Show distribution
    label_counts = {}
    for _, label in training_data:
        label_counts[label] = label_counts.get(label, 0) + 1
    
    logger.info("High-quality label distribution:")
    for category, idx in categories.items():
        logger.info(f"  {category}: {label_counts.get(idx, 0)} samples")
    
    return training_data

def train_perfected_model():
    """Train perfected model using optimal architecture with enhanced data"""
    
    try:
        import tensorflow as tf
        from tensorflow.keras.models import Sequential
        from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, Dropout
        from tensorflow.keras.preprocessing.text import Tokenizer
        from tensorflow.keras.preprocessing.sequence import pad_sequences
        from sklearn.metrics import classification_report, confusion_matrix
        
        logger.info("Starting perfected model training...")
        
        # Create high-quality training data
        training_data = create_high_quality_synthetic_data()
        
        # Separate texts and labels
        texts = [item[0] for item in training_data]
        labels = [item[1] for item in training_data]
        
        # Convert to DataFrame
        df = pd.DataFrame({'text': texts, 'label': labels})
        logger.info(f"Perfected dataset shape: {df.shape}")
        
        # Split data with stratification
        X_train, X_test, y_train, y_test = train_test_split(
            df['text'], df['label'], test_size=0.2, random_state=42, stratify=df['label']
        )
        
        # Use OPTIMAL parameters from fixed model (not enhanced)
        logger.info("Using optimal tokenization parameters...")
        max_words = 5000  # Same as fixed model (not 7000)
        max_len = 60      # Same as fixed model (not 80)
        
        tokenizer = Tokenizer(num_words=max_words, oov_token='<OOV>')
        tokenizer.fit_on_texts(X_train)
        
        # Convert text to sequences
        X_train_seq = tokenizer.texts_to_sequences(X_train)
        X_test_seq = tokenizer.texts_to_sequences(X_test)
        
        # Pad sequences
        X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post', truncating='post')
        X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post', truncating='post')
        
        logger.info(f"Perfected training shape: {X_train_pad.shape}")
        logger.info(f"Perfected test shape: {X_test_pad.shape}")
        
        # Calculate class weights
        class_weights = compute_class_weight(
            'balanced', 
            classes=np.unique(y_train), 
            y=y_train
        )
        class_weight_dict = dict(zip(np.unique(y_train), class_weights))
        logger.info(f"Perfected class weights: {class_weight_dict}")
        
        # Use OPTIMAL architecture from fixed model (not over-engineered)
        logger.info("Building perfected model with optimal architecture...")
        
        model = Sequential([
            Embedding(max_words, 64),  # Same as fixed model (not 128)
            GlobalAveragePooling1D(),
            Dense(128, activation='relu'),  # Same as fixed model
            Dropout(0.5),
            Dense(64, activation='relu'),   # Same as fixed model
            Dropout(0.3),
            Dense(32, activation='relu'),   # Same as fixed model  
            Dropout(0.2),
            Dense(6, activation='softmax')  # 6 categories
        ])
        
        model.compile(
            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy']
        )
        
        logger.info("Perfected model architecture:")
        model.summary()
        
        # Use optimal training configuration
        logger.info("Training perfected model...")
        from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
        
        callbacks = [
            EarlyStopping(
                monitor='val_accuracy',
                patience=15,  # More patience for better convergence
                restore_best_weights=True,
                verbose=1
            ),
            ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.5,
                patience=7,
                min_lr=0.00001,
                verbose=1
            ),
            ModelCheckpoint(
                'models/best_perfected_model.keras',
                monitor='val_accuracy',
                save_best_only=True,
                verbose=1
            )
        ]
        
        history = model.fit(
            X_train_pad, y_train,
            batch_size=32,  # Same as fixed model (not 64)
            epochs=40,  # Sufficient epochs with early stopping
            validation_split=0.2,
            class_weight=class_weight_dict,
            callbacks=callbacks,
            verbose=1
        )
        
        # Evaluate model
        logger.info("Evaluating perfected model...")
        test_loss, test_acc = model.evaluate(X_test_pad, y_test, verbose=0)
        logger.info(f"Perfected test accuracy: {test_acc:.4f}")
        
        # Detailed predictions analysis
        y_pred = model.predict(X_test_pad, verbose=0)
        y_pred_classes = np.argmax(y_pred, axis=1)
        
        # Classification report
        category_names = ['INBOX', 'SPAM', 'OTP', 'BANKING', 'ECOMMERCE', 'NEEDS_REVIEW']
        print("\nPerfected Classification Report:")
        print(classification_report(y_test, y_pred_classes, target_names=category_names, zero_division=0))
        
        # Confusion matrix
        cm = confusion_matrix(y_test, y_pred_classes)
        logger.info("Perfected Confusion Matrix:")
        logger.info(f"Categories: {category_names}")
        for i, row in enumerate(cm):
            logger.info(f"{category_names[i]}: {row}")
        
        # Save model
        models_dir = Path("models")
        models_dir.mkdir(exist_ok=True)
        
        model_path = models_dir / "perfected_sms_classifier.keras"
        model.save(str(model_path))
        logger.info(f"Perfected model saved to {model_path}")
        
        # Save tokenizer
        import pickle
        tokenizer_path = models_dir / "perfected_tokenizer.pkl"
        with open(tokenizer_path, 'wb') as f:
            pickle.dump(tokenizer, f)
        logger.info(f"Perfected tokenizer saved to {tokenizer_path}")
        
        # Convert to TensorFlow Lite
        logger.info("Converting perfected model to TensorFlow Lite...")
        converter = tf.lite.TFLiteConverter.from_keras_model(model)
        
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        converter.target_spec.supported_ops = [
            tf.lite.OpsSet.TFLITE_BUILTINS,
            tf.lite.OpsSet.SELECT_TF_OPS
        ]
        converter.target_spec.supported_types = [tf.float32]
        
        tflite_model = converter.convert()
        
        tflite_path = models_dir / "perfected_sms_classifier.tflite"
        with open(tflite_path, 'wb') as f:
            f.write(tflite_model)
        
        size_mb = len(tflite_model) / (1024 * 1024)
        logger.info(f"Perfected TFLite model saved to {tflite_path}")
        logger.info(f"Perfected model size: {size_mb:.2f}MB")
        
        # Test TFLite model
        logger.info("Testing perfected TensorFlow Lite model...")
        interpreter = tf.lite.Interpreter(model_content=tflite_model)
        interpreter.allocate_tensors()
        
        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()
        
        # Comprehensive test samples
        test_samples = [
            ("Your OTP is 456789. Valid for 10 minutes. Do not share.", "OTP"),
            ("üéâ CONGRATULATIONS! You've won Rs.100000! Call 9876543210 NOW!", "SPAM"),
            ("Hi, are you free for lunch today? Let me know!", "INBOX"),
            ("Rs.15000 debited from A/c XX1234 on 15-JAN-25. Balance: Rs.45000", "BANKING"),
            ("Your Amazon order #12345678 is out for delivery. Expected by 6 PM.", "ECOMMERCE"),
            ("Please update your profile details to continue service.", "NEEDS_REVIEW"),
            ("URGENT: Double your money in 30 days! Invest Rs.10000 get Rs.20000", "SPAM"),
            ("Low balance alert: Your HDFC A/c XX1234 balance is Rs.500", "BANKING"),
            ("Hi dude, movie tonight at 8 PM? Let me know ASAP!", "INBOX"),
            ("Your Swiggy order from McDonald's will arrive in 25 minutes", "ECOMMERCE")
        ]
        
        logger.info("Perfected sample predictions:")
        correct_predictions = 0
        for text, expected in test_samples:
            # Preprocess
            sample_seq = tokenizer.texts_to_sequences([text])
            sample_pad = pad_sequences(sample_seq, maxlen=max_len, padding='post', truncating='post')
            
            # Resize interpreter
            input_shape = sample_pad.shape
            interpreter.resize_tensor_input(input_details[0]['index'], input_shape)
            interpreter.allocate_tensors()
            
            # Predict
            interpreter.set_tensor(input_details[0]['index'], sample_pad.astype(np.float32))
            interpreter.invoke()
            
            output_data = interpreter.get_tensor(output_details[0]['index'])
            predicted_class = np.argmax(output_data[0])
            confidence = np.max(output_data[0])
            predicted_category = category_names[predicted_class]
            
            is_correct = predicted_category == expected
            if is_correct:
                correct_predictions += 1
            
            logger.info(f"  Text: {text[:50]}...")
            logger.info(f"  Expected: {expected}, Predicted: {predicted_category} ({confidence:.3f}) {'‚úì' if is_correct else '‚úó'}")
        
        sample_accuracy = correct_predictions / len(test_samples)
        logger.info(f"Perfected sample test accuracy: {sample_accuracy:.1%}")
        
        # Create comprehensive metadata
        metadata = {
            'model_type': 'Perfected Enhanced Dense Network',
            'categories': category_names,
            'max_words': max_words,
            'max_len': max_len,
            'test_accuracy': float(test_acc),
            'sample_test_accuracy': float(sample_accuracy),
            'model_size_mb': float(size_mb),
            'training_samples': len(training_data),
            'samples_per_category': len(training_data) // 6,
            'architecture': 'Embedding(64) + GlobalAveragePooling1D + 3x Dense layers (128,64,32)',
            'features': [
                'high_quality_synthetic_data',
                'optimal_vocabulary_5000',
                'optimal_sequences_60',
                'optimal_architecture_from_fixed',
                'enhanced_data_diversity',
                'balanced_dataset',
                'class_weights', 
                'early_stopping',
                'learning_rate_scheduling',
                'model_checkpointing',
                'dynamic_batch_size'
            ],
            'improvements': [
                '200_samples_per_category',
                'cleaner_distinctive_patterns',
                'focused_realistic_templates',
                'optimal_hyperparameters',
                'best_of_both_approaches'
            ],
            'class_weights': {str(k): float(v) for k, v in class_weight_dict.items()}
        }
        
        import json
        metadata_path = models_dir / "perfected_model_metadata.json"
        with open(metadata_path, 'w') as f:
            json.dump(metadata, f, indent=2)
        logger.info(f"Perfected metadata saved to {metadata_path}")
        
        logger.info("üéâ Perfected training completed successfully!")
        logger.info(f"üì± Mobile-ready perfected model: {size_mb:.2f}MB")
        logger.info(f"üéØ Test accuracy: {test_acc:.1%}")
        logger.info(f"üéØ Sample test accuracy: {sample_accuracy:.1%}")
        
        return {
            'model_path': str(model_path),
            'tflite_path': str(tflite_path),
            'tokenizer_path': str(tokenizer_path),
            'test_accuracy': test_acc,
            'sample_accuracy': sample_accuracy,
            'model_size_mb': size_mb
        }
        
    except Exception as e:
        logger.error(f"Perfected training failed: {e}")
        import traceback
        traceback.print_exc()
        return None

def main():
    """Main perfected training function"""
    logger.info("üöÄ Perfected Enhanced SMS Classifier Training")
    logger.info("=" * 80)
    logger.info("üéØ Target: Achieve 98%+ accuracy with enhanced diverse data")
    logger.info("üîß Strategy: Use optimal architecture from Fixed model + enhanced data")
    logger.info("=" * 80)
    
    # Train perfected model
    result = train_perfected_model()
    
    if result:
        print("\n" + "="*80)
        print("‚úÖ SUCCESS: Perfected Enhanced Mobile SMS Classifier Trained!")
        print("="*80)
        print(f"üìÅ Model files:")
        print(f"  ‚Ä¢ Keras model: {result['model_path']}")
        print(f"  ‚Ä¢ TFLite model: {result['tflite_path']} ({result['model_size_mb']:.2f}MB)")
        print(f"  ‚Ä¢ Tokenizer: {result['tokenizer_path']}")
        print(f"üéØ Test accuracy: {result['test_accuracy']:.1%}")
        print(f"üéØ Sample test accuracy: {result['sample_accuracy']:.1%}")
        print(f"üì± Ready for Android integration!")
        print("="*80)
        print(f"üîß Next steps:")
        print(f"  1. Copy {Path(result['tflite_path']).name} to android/app/src/main/assets/")
        print(f"  2. Update Android integration to use perfected model")
        print(f"  3. Compare performance with fixed model")
        print("="*80)
        print("üéØ PERFECTED APPROACH:")
        print("  ‚Ä¢ Enhanced diverse data (1200 samples, 200 per category)")
        print("  ‚Ä¢ Optimal architecture from Fixed model (not over-engineered)")
        print("  ‚Ä¢ High-quality synthetic patterns (cleaner, more distinctive)")
        print("  ‚Ä¢ Proven hyperparameters (5000 vocab, 60 length)")
        print("  ‚Ä¢ Advanced training (early stopping, LR scheduling)")
        print("="*80)
    else:
        print("\n‚ùå Perfected training failed. Please check the logs above.")

if __name__ == "__main__":
    main()